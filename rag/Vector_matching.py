import os
import json
import numpy as np
from openai import OpenAI
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡ï¼Œä¸»è¦ä¸ºäº†è·å–APIå¯†é’¥
load_dotenv(dotenv_path=os.path.join(os.path.dirname(__file__), '..', 'main', '.env'))

class DashScopeEmbeddingGenerator:
    """é€šä¹‰åƒé—®å‘é‡ç”Ÿæˆå™¨"""
    def __init__(self, model="text-embedding-v4", dimensions=1024, api_key=None, base_url=None):
        """
        åˆå§‹åŒ–å‘é‡ç”Ÿæˆå™¨ã€‚
        :param model: ä½¿ç”¨çš„æ¨¡å‹åç§°ã€‚
        :param dimensions: å‘é‡ç»´åº¦ã€‚
        :param api_key: APIå¯†é’¥ï¼Œå¦‚æœæœªæä¾›ï¼Œåˆ™ä»ç¯å¢ƒå˜é‡ DASHSCOPE_API_KEY è·å–ã€‚
        :param base_url: APIçš„åŸºç¡€URLã€‚
        """
        self.client = OpenAI(
            api_key=api_key or os.getenv("DASHSCOPE_API_KEY"),
            base_url=base_url or "https://dashscope.aliyuncs.com/compatible-mode/v1",
        )
        self.model = model
        self.dimensions = dimensions

    def get_embedding(self, text: str) -> list[float]:
        """
        è·å–å•ä¸ªæ–‡æœ¬çš„å‘é‡ã€‚
        :param text: è¾“å…¥çš„æ–‡æœ¬ã€‚
        :return: æ–‡æœ¬çš„å‘é‡è¡¨ç¤ºã€‚
        """
        # --- å…³é”®ä¿®æ”¹ï¼šç¡®ä¿å°† dimensions å‚æ•°ä¼ é€’ç»™ API ---
        response = self.client.embeddings.create(
            model=self.model,
            input=[text],
            dimensions=self.dimensions
        )
        return response.data[0].embedding

class VectorSearcher:
    """å‘é‡æ£€ç´¢å™¨ï¼Œç”¨äºåœ¨çŸ¥è¯†åº“ä¸­è¿›è¡Œç›¸ä¼¼åº¦æœç´¢"""
    def __init__(self, db_path: str, embedding_model: str = "text-embedding-v4", dimensions: int = 1024):
        """
        åˆå§‹åŒ–å‘é‡æ£€ç´¢å™¨ã€‚
        :param db_path: çŸ¥è¯†åº“æ–‡ä»¶è·¯å¾„ (embeddings.json)ã€‚
        :param embedding_model: ç”¨äºç”ŸæˆæŸ¥è¯¢å‘é‡çš„æ¨¡å‹åç§°ã€‚
        :param dimensions: å‘é‡ç»´åº¦ã€‚
        """
        self.db_path = db_path
        self.knowledge_base = self._load_knowledge_base()
        # --- ç¡®ä¿å°† dimensions ä¼ é€’ç»™ç”Ÿæˆå™¨ ---
        self.embedding_generator = DashScopeEmbeddingGenerator(model=embedding_model, dimensions=dimensions)

    def _load_knowledge_base(self) -> list:
        """ä»JSONæ–‡ä»¶åŠ è½½çŸ¥è¯†åº“ã€‚"""
        try:
            with open(self.db_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            print(f"é”™è¯¯ï¼šçŸ¥è¯†åº“æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œè·¯å¾„ï¼š{self.db_path}")
            return []
        except json.JSONDecodeError:
            print(f"é”™è¯¯ï¼šæ— æ³•è§£æçŸ¥è¯†åº“æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥JSONæ ¼å¼ï¼š{self.db_path}")
            return []

    @staticmethod
    def _cosine_similarity(vec1: np.ndarray, vec2: np.ndarray) -> float:
        """è®¡ç®—ä¸¤ä¸ªå‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦ã€‚"""
        vec1 = np.array(vec1)
        vec2 = np.array(vec2)
        dot_product = np.dot(vec1, vec2)
        norm_vec1 = np.linalg.norm(vec1)
        norm_vec2 = np.linalg.norm(vec2)
        if norm_vec1 == 0 or norm_vec2 == 0:
            return 0.0
        return dot_product / (norm_vec1 * norm_vec2)

    def search(self, user_query, top_k=3, similarity_threshold=0.8, debug=False):
        """
        åœ¨çŸ¥è¯†åº“ä¸­æœç´¢ä¸ç”¨æˆ·æŸ¥è¯¢æœ€ç›¸å…³çš„æ–‡æœ¬å—ã€‚
        æ–°å¢debugæ¨¡å¼ï¼Œç”¨äºæ‰“å°æ‰€æœ‰æ½œåœ¨åŒ¹é…é¡¹çš„ç›¸ä¼¼åº¦ã€‚
        """
        query_vector = self.embedding_generator.get_embedding(user_query)
        
        all_matches = []
        for item in self.knowledge_base:
            # ç¡®ä¿å‘é‡å­˜åœ¨ä¸”éç©º
            if 'vector' not in item or not item['vector']:
                continue
            
            similarity = self._cosine_similarity(query_vector, item['vector'])
            all_matches.append({
                'id': item.get('id', 'N/A'),
                'text': item.get('text', 'N/A'),
                'similarity': similarity
            })

        # æŒ‰ç›¸ä¼¼åº¦å¯¹æ‰€æœ‰å€™é€‰é¡¹è¿›è¡Œæ’åº
        sorted_matches = sorted(all_matches, key=lambda x: x['similarity'], reverse=True)

        # å¦‚æœå¼€å¯è°ƒè¯•æ¨¡å¼ï¼Œæ‰“å°Top5çš„åŸå§‹åŒ¹é…ä¿¡æ¯
        if debug:
            print("\n--- [DEBUG] RAG Search Internals ---")
            print(f"Query: '{user_query}'")
            print(f"Threshold: {similarity_threshold}")
            print("Top 5 potential matches (regardless of threshold):")
            for i, match in enumerate(sorted_matches[:5]):
                print(f"  {i+1}. Sim: {match['similarity']:.4f}, ID: {match['id']}, Text: '{match['text'][:80]}...'")
            print("-------------------------------------\n")

        # æ ¹æ®é˜ˆå€¼è¿‡æ»¤ç»“æœ
        final_results = [match for match in sorted_matches if match['similarity'] >= similarity_threshold]
        
        return final_results[:top_k]

# ä¸»ç¨‹åºå…¥å£ç¤ºä¾‹ä»£ç ä¿æŒä¸å˜
if __name__ == "__main__":
    # çŸ¥è¯†åº“æ–‡ä»¶è·¯å¾„
    project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    db_file_path = os.path.join(project_root, 'db', 'embeddings.json')

    # æ£€æŸ¥çŸ¥è¯†åº“æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(db_file_path):
        print(f"é”™è¯¯ï¼šçŸ¥è¯†åº“æ–‡ä»¶ 'embeddings.json' åœ¨è·¯å¾„ '{db_file_path}' ä¸­ä¸å­˜åœ¨ã€‚")
        print("è¯·å…ˆç¡®ä¿çŸ¥è¯†åº“æ–‡ä»¶å·²æ­£ç¡®ç”Ÿæˆå¹¶æ”¾ç½®åœ¨æŒ‡å®šç›®å½•ã€‚")
    else:
        # --- ç¡®ä¿åœ¨åˆå§‹åŒ–æ—¶ä¼ å…¥æ­£ç¡®çš„æ¨¡å‹å’Œç»´åº¦ ---
        searcher = VectorSearcher(db_path=db_file_path, embedding_model="text-embedding-v4", dimensions=1024)
        
        # å®šä¹‰ç”¨æˆ·é—®é¢˜
        user_query = "æ°´è¡¨ç™»è®°éœ€è¦ä»€ä¹ˆææ–™ï¼Ÿ"


        
        # æ‰§è¡Œæœç´¢
        results = searcher.search(user_query, top_k=3, similarity_threshold=5)
        
        # æ‰“å°ç»“æœ
        print(f"\nğŸ” å¯¹äºé—®é¢˜: '{user_query}'")
        if results:
            print("âœ… æ‰¾åˆ°ä»¥ä¸‹ç›¸å…³å†…å®¹:")
            for result in results:
                # ä»ç»“æœä¸­è·å– 'text' å­—æ®µ
                print(f"   - [ç›¸ä¼¼åº¦: {result['similarity']:.4f}] åŒ¹é…å†…å®¹: {result['text']}")
        else:
            print("âŒ æœªæ‰¾åˆ°ç›¸å…³å†…å®¹ã€‚")